{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown --id 1qiUDDoYyRLBiKOoYWdFl_5WByHE8Cugu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 59\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_state)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'Auto_MPG_data.csv'\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns='MPG').values\n",
    "y = dataset['MPG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "random_state = 2\n",
    "is_shuffle = True\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=val_size,\n",
    "    random_state=random_state,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_val = normalizer.transform(X_val)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dims, hidden_dims)\n",
    "        self.linear2 = nn.Linear(hidden_dims, hidden_dims)\n",
    "        self.output = nn.Linear(hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.tanh(x)\n",
    "        out = self.output(x)\n",
    "        \n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, input_dims, hidden_dims, output_dim):\n",
    "#         super().__init__()\n",
    "#         self.output = nn.Linear(input_dims, output_dim)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.output(x)\n",
    "        \n",
    "#         return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = X_train.shape[1]\n",
    "output_dims = 1\n",
    "hidden_dims = 64\n",
    "\n",
    "model = MLP(input_dims=input_dims, hidden_dims=hidden_dims, output_dim=output_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    y_true = torch.Tensor(y_true).to(device)\n",
    "    y_pred = torch.Tensor(y_pred).to(device)\n",
    "    mean_true = torch.mean(y_true)\n",
    "    ss_tot = torch.sum((y_true - mean_true)**2)\n",
    "    ss_res = torch.sum((y_true - y_pred)**2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\tTraining loss: 254.293 \tValidation loss: 21.529\n",
      "\n",
      "EPOCH 2:\tTraining loss: 19.421 \tValidation loss: 18.321\n",
      "\n",
      "EPOCH 3:\tTraining loss: 15.635 \tValidation loss: 16.484\n",
      "\n",
      "EPOCH 4:\tTraining loss: 13.377 \tValidation loss: 14.794\n",
      "\n",
      "EPOCH 5:\tTraining loss: 12.669 \tValidation loss: 18.788\n",
      "\n",
      "EPOCH 6:\tTraining loss: 10.046 \tValidation loss: 11.555\n",
      "\n",
      "EPOCH 7:\tTraining loss: 9.034 \tValidation loss: 9.819\n",
      "\n",
      "EPOCH 8:\tTraining loss: 9.211 \tValidation loss: 9.071\n",
      "\n",
      "EPOCH 9:\tTraining loss: 8.677 \tValidation loss: 8.233\n",
      "\n",
      "EPOCH 10:\tTraining loss: 8.233 \tValidation loss: 9.749\n",
      "\n",
      "EPOCH 11:\tTraining loss: 7.408 \tValidation loss: 7.966\n",
      "\n",
      "EPOCH 12:\tTraining loss: 7.820 \tValidation loss: 8.778\n",
      "\n",
      "EPOCH 13:\tTraining loss: 9.632 \tValidation loss: 10.015\n",
      "\n",
      "EPOCH 14:\tTraining loss: 8.666 \tValidation loss: 7.679\n",
      "\n",
      "EPOCH 15:\tTraining loss: 7.179 \tValidation loss: 7.526\n",
      "\n",
      "EPOCH 16:\tTraining loss: 7.926 \tValidation loss: 8.895\n",
      "\n",
      "EPOCH 17:\tTraining loss: 7.862 \tValidation loss: 7.429\n",
      "\n",
      "EPOCH 18:\tTraining loss: 6.972 \tValidation loss: 8.447\n",
      "\n",
      "EPOCH 19:\tTraining loss: 7.405 \tValidation loss: 8.256\n",
      "\n",
      "EPOCH 20:\tTraining loss: 7.454 \tValidation loss: 10.278\n",
      "\n",
      "EPOCH 21:\tTraining loss: 7.113 \tValidation loss: 6.865\n",
      "\n",
      "EPOCH 22:\tTraining loss: 7.118 \tValidation loss: 11.374\n",
      "\n",
      "EPOCH 23:\tTraining loss: 8.272 \tValidation loss: 7.831\n",
      "\n",
      "EPOCH 24:\tTraining loss: 6.646 \tValidation loss: 6.635\n",
      "\n",
      "EPOCH 25:\tTraining loss: 6.624 \tValidation loss: 7.041\n",
      "\n",
      "EPOCH 26:\tTraining loss: 6.955 \tValidation loss: 7.243\n",
      "\n",
      "EPOCH 27:\tTraining loss: 7.409 \tValidation loss: 7.849\n",
      "\n",
      "EPOCH 28:\tTraining loss: 6.747 \tValidation loss: 8.054\n",
      "\n",
      "EPOCH 29:\tTraining loss: 7.683 \tValidation loss: 7.510\n",
      "\n",
      "EPOCH 30:\tTraining loss: 7.306 \tValidation loss: 6.384\n",
      "\n",
      "EPOCH 31:\tTraining loss: 6.486 \tValidation loss: 7.086\n",
      "\n",
      "EPOCH 32:\tTraining loss: 6.429 \tValidation loss: 6.932\n",
      "\n",
      "EPOCH 33:\tTraining loss: 6.095 \tValidation loss: 6.854\n",
      "\n",
      "EPOCH 34:\tTraining loss: 6.197 \tValidation loss: 7.168\n",
      "\n",
      "EPOCH 35:\tTraining loss: 6.970 \tValidation loss: 6.246\n",
      "\n",
      "EPOCH 36:\tTraining loss: 6.602 \tValidation loss: 8.422\n",
      "\n",
      "EPOCH 37:\tTraining loss: 5.954 \tValidation loss: 6.112\n",
      "\n",
      "EPOCH 38:\tTraining loss: 6.376 \tValidation loss: 6.408\n",
      "\n",
      "EPOCH 39:\tTraining loss: 5.895 \tValidation loss: 7.765\n",
      "\n",
      "EPOCH 40:\tTraining loss: 6.471 \tValidation loss: 7.116\n",
      "\n",
      "EPOCH 41:\tTraining loss: 5.861 \tValidation loss: 6.262\n",
      "\n",
      "EPOCH 42:\tTraining loss: 5.649 \tValidation loss: 6.133\n",
      "\n",
      "EPOCH 43:\tTraining loss: 5.817 \tValidation loss: 6.320\n",
      "\n",
      "EPOCH 44:\tTraining loss: 6.064 \tValidation loss: 6.088\n",
      "\n",
      "EPOCH 45:\tTraining loss: 6.543 \tValidation loss: 6.336\n",
      "\n",
      "EPOCH 46:\tTraining loss: 5.729 \tValidation loss: 6.479\n",
      "\n",
      "EPOCH 47:\tTraining loss: 6.275 \tValidation loss: 6.452\n",
      "\n",
      "EPOCH 48:\tTraining loss: 5.939 \tValidation loss: 6.234\n",
      "\n",
      "EPOCH 49:\tTraining loss: 5.319 \tValidation loss: 7.265\n",
      "\n",
      "EPOCH 50:\tTraining loss: 5.814 \tValidation loss: 5.806\n",
      "\n",
      "EPOCH 51:\tTraining loss: 5.838 \tValidation loss: 6.918\n",
      "\n",
      "EPOCH 52:\tTraining loss: 5.858 \tValidation loss: 6.134\n",
      "\n",
      "EPOCH 53:\tTraining loss: 5.138 \tValidation loss: 5.674\n",
      "\n",
      "EPOCH 54:\tTraining loss: 5.300 \tValidation loss: 5.847\n",
      "\n",
      "EPOCH 55:\tTraining loss: 6.138 \tValidation loss: 8.235\n",
      "\n",
      "EPOCH 56:\tTraining loss: 5.858 \tValidation loss: 5.948\n",
      "\n",
      "EPOCH 57:\tTraining loss: 5.659 \tValidation loss: 7.141\n",
      "\n",
      "EPOCH 58:\tTraining loss: 5.632 \tValidation loss: 6.513\n",
      "\n",
      "EPOCH 59:\tTraining loss: 5.509 \tValidation loss: 6.092\n",
      "\n",
      "EPOCH 60:\tTraining loss: 5.797 \tValidation loss: 6.892\n",
      "\n",
      "EPOCH 61:\tTraining loss: 5.188 \tValidation loss: 5.568\n",
      "\n",
      "EPOCH 62:\tTraining loss: 5.059 \tValidation loss: 6.149\n",
      "\n",
      "EPOCH 63:\tTraining loss: 5.578 \tValidation loss: 6.308\n",
      "\n",
      "EPOCH 64:\tTraining loss: 6.614 \tValidation loss: 6.794\n",
      "\n",
      "EPOCH 65:\tTraining loss: 5.196 \tValidation loss: 6.279\n",
      "\n",
      "EPOCH 66:\tTraining loss: 4.911 \tValidation loss: 5.939\n",
      "\n",
      "EPOCH 67:\tTraining loss: 5.086 \tValidation loss: 7.683\n",
      "\n",
      "EPOCH 68:\tTraining loss: 5.611 \tValidation loss: 6.378\n",
      "\n",
      "EPOCH 69:\tTraining loss: 5.150 \tValidation loss: 5.906\n",
      "\n",
      "EPOCH 70:\tTraining loss: 4.782 \tValidation loss: 6.177\n",
      "\n",
      "EPOCH 71:\tTraining loss: 5.115 \tValidation loss: 7.051\n",
      "\n",
      "EPOCH 72:\tTraining loss: 5.632 \tValidation loss: 7.044\n",
      "\n",
      "EPOCH 73:\tTraining loss: 5.062 \tValidation loss: 9.539\n",
      "\n",
      "EPOCH 74:\tTraining loss: 5.306 \tValidation loss: 5.904\n",
      "\n",
      "EPOCH 75:\tTraining loss: 5.197 \tValidation loss: 5.824\n",
      "\n",
      "EPOCH 76:\tTraining loss: 5.333 \tValidation loss: 6.319\n",
      "\n",
      "EPOCH 77:\tTraining loss: 5.227 \tValidation loss: 6.122\n",
      "\n",
      "EPOCH 78:\tTraining loss: 4.916 \tValidation loss: 5.892\n",
      "\n",
      "EPOCH 79:\tTraining loss: 4.720 \tValidation loss: 5.734\n",
      "\n",
      "EPOCH 80:\tTraining loss: 4.752 \tValidation loss: 5.883\n",
      "\n",
      "EPOCH 81:\tTraining loss: 4.916 \tValidation loss: 5.311\n",
      "\n",
      "EPOCH 82:\tTraining loss: 4.776 \tValidation loss: 5.932\n",
      "\n",
      "EPOCH 83:\tTraining loss: 4.664 \tValidation loss: 5.645\n",
      "\n",
      "EPOCH 84:\tTraining loss: 5.508 \tValidation loss: 7.052\n",
      "\n",
      "EPOCH 85:\tTraining loss: 5.314 \tValidation loss: 5.782\n",
      "\n",
      "EPOCH 86:\tTraining loss: 4.859 \tValidation loss: 5.785\n",
      "\n",
      "EPOCH 87:\tTraining loss: 4.866 \tValidation loss: 6.543\n",
      "\n",
      "EPOCH 88:\tTraining loss: 4.578 \tValidation loss: 5.467\n",
      "\n",
      "EPOCH 89:\tTraining loss: 4.814 \tValidation loss: 6.003\n",
      "\n",
      "EPOCH 90:\tTraining loss: 5.002 \tValidation loss: 8.933\n",
      "\n",
      "EPOCH 91:\tTraining loss: 5.294 \tValidation loss: 6.285\n",
      "\n",
      "EPOCH 92:\tTraining loss: 4.962 \tValidation loss: 5.585\n",
      "\n",
      "EPOCH 93:\tTraining loss: 4.832 \tValidation loss: 5.575\n",
      "\n",
      "EPOCH 94:\tTraining loss: 4.636 \tValidation loss: 5.768\n",
      "\n",
      "EPOCH 95:\tTraining loss: 4.423 \tValidation loss: 5.557\n",
      "\n",
      "EPOCH 96:\tTraining loss: 4.318 \tValidation loss: 5.696\n",
      "\n",
      "EPOCH 97:\tTraining loss: 4.295 \tValidation loss: 5.810\n",
      "\n",
      "EPOCH 98:\tTraining loss: 4.738 \tValidation loss: 5.484\n",
      "\n",
      "EPOCH 99:\tTraining loss: 4.678 \tValidation loss: 8.410\n",
      "\n",
      "EPOCH 100:\tTraining loss: 4.761 \tValidation loss: 6.272\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_target = []\n",
    "    val_target = []\n",
    "    train_predict = []\n",
    "    val_predict = []\n",
    "    model.train()\n",
    "    \n",
    "    for X_samples, y_samples in train_loader:\n",
    "        X_samples = X_samples.to(device)\n",
    "        y_samples = y_samples.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_samples)\n",
    "        train_predict += outputs.tolist()\n",
    "        train_target += y_samples.tolist()\n",
    "        loss = criterion(outputs, y_samples)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_r2.append(r_squared(train_target, train_predict))\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_samples, y_samples in val_loader:\n",
    "            X_samples = X_samples.to(device)\n",
    "            y_samples = y_samples.to(device)\n",
    "            outputs = model(X_samples)\n",
    "            \n",
    "            val_predict += outputs.tolist()\n",
    "            val_target += y_samples.tolist()\n",
    "            loss = criterion(outputs, y_samples)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_r2.append(r_squared(val_target, val_predict))\n",
    "    print(f'\\nEPOCH {epoch + 1}:\\tTraining loss: {train_loss:.3f} \\tValidation loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set:\n",
      "R2: 0.820570707321167\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(X_test)\n",
    "    test_set_r2 = r_squared(y_hat, y_test)\n",
    "    print('Evaluation on test set:')\n",
    "    print(f'R2: {test_set_r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
