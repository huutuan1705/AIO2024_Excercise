{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/all-data.csv'\n",
    "headers = ['sentiment', 'content']\n",
    "df = pd.read_csv(\n",
    "    dataset_path, names=headers, encoding='ISO-8859-1'\n",
    ")\n",
    "\n",
    "classes = {\n",
    "    class_name: idx for idx, class_name in enumerate(df['sentitment'].unique().tolist())\n",
    "}\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: classes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stop_words = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def text_normalize(text):\n",
    "    text = text.lower()\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in english_stop_words])\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split(' ')])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lambda x: text_normalize(x))\n",
    "vocab = []\n",
    "for sentence in df['content'].tolist():\n",
    "    tokens = sentence.split()\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "            \n",
    "vocab.append('UNK')\n",
    "vocab.append('PAD')\n",
    "\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text, word_to_idx, max_seq_len):\n",
    "    tokens = []\n",
    "    for w in text.split():\n",
    "        try:\n",
    "            w_ids = word_to_idx[w]\n",
    "        except:\n",
    "            w_ids = word_to_idx['UNK']\n",
    "        tokens.append(w_ids)\n",
    "        \n",
    "    if len(tokens) < max_seq_len:\n",
    "        tokens += [word_to_idx['PAD']] * (max_seq_len - len(tokens))\n",
    "    elif len(tokens) > max_seq_len:\n",
    "        tokens = tokens[:max_seq_len]\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "text_size = 0.125\n",
    "is_shuffle = True\n",
    "\n",
    "texts = df['content'].tolist()\n",
    "lables = df['sentiment'].tolist()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    texts, lables,\n",
    "    text_size=val_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    text_sizev=val_size,\n",
    "    random_state=seed,\n",
    "    shuffle=is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialNews(Dataset):\n",
    "    def __init__(self, X, y, word_to_idx, max_seq_len, transform=None):\n",
    "        self.texts = X\n",
    "        self.labels = y\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            text = self.transform(\n",
    "                text, self.word_to_idx, self.max_seq_len\n",
    "            )\n",
    "        text = torch.tensor(text)\n",
    "        \n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 32\n",
    "train_dataset = FinancialNews(\n",
    "    X_train, y_train, \n",
    "    word_to_idx=word_to_idx,\n",
    "    max_seq_len=max_seq_len,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = FinancialNews(\n",
    "    X_val, y_val, \n",
    "    word_to_idx=word_to_idx,\n",
    "    max_seq_len=max_seq_len,\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset = FinancialNews(\n",
    "    X_test, y_test, \n",
    "    word_to_idx=word_to_idx,\n",
    "    max_seq_len=max_seq_len,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_batch_size = 128\n",
    "test_batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
