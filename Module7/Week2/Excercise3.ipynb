{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "data_dir = kagglehub.dataset_download(\"andrewmvd/dog-cat-detection\")\n",
    "print(\"Path to dataset file: \", data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models.resnet import ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, annotations_dir, image_dir, transform=None):\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = self.filter_images_with_multiple_objects()\n",
    "        \n",
    "    def filter_images_with_multiple_objects(self):\n",
    "        valid_image_files = []\n",
    "        for f in os.listdir(self.image_dir):\n",
    "            if os.path.isfile(os.path.join(self.image_dir, f)):\n",
    "                img_name = f\n",
    "                annotation_name = os.path.splitext(img_name)[0] +\".xml\"\n",
    "                annotation_path = os.path.join(self.annotations_dir, annotation_name)\n",
    "                \n",
    "                # Keep iomages that have single object\n",
    "                if self.count_objects_in_annotation(annotation_path) == 1:\n",
    "                    valid_image_files.append(img_name)\n",
    "        return valid_image_files\n",
    "    \n",
    "    def count_objects_in_annotation(self, annotation_path):\n",
    "        try:\n",
    "            tree = ET.parse(annotation_path)\n",
    "            root = tree.getroot()\n",
    "            count = 0\n",
    "            for obj in root.findall(\"object\"):\n",
    "                count += 1\n",
    "        except FileNotFoundError:\n",
    "            return 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img1_name = self.image_files[idx]\n",
    "        img1_path = os.path.join(self.image_dir, img1_name)\n",
    "        \n",
    "        annotation_name = os.path.splitext(img1_name)\n",
    "        img1_annotations = self.parse_annotation(\n",
    "            os.path.join(self.annotations_dir, annotation_name)\n",
    "        )\n",
    "        idx2 = random.randint(0, len(self.image_files) - 1)\n",
    "        img2_file = self.image_files[idx2]\n",
    "        img2_path = os.path.join(self.image_dir, img2_file)\n",
    "        \n",
    "        annotation_name = os.path.splitext(img2_file)[0] + \".xml\"\n",
    "        img2_annotations = self.parse_annotation(\n",
    "            os.path.join(self.annotations_dir, annotation_name)\n",
    "        )\n",
    "        \n",
    "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
    "        img2 = Image.open(img1_path).convert(\"RGB\")\n",
    "\n",
    "        merged_image = Image.new(\"RGB\", (img1.width + img2.width, max(img1.height, img2.height)))\n",
    "        \n",
    "        merged_image.paste(img1, (0, 0))\n",
    "        merged_image.paste(img2, (img1.width, 0))\n",
    "        merged_w = img1.width + img2.width\n",
    "        merged_h = max(img1.height, img2.height)\n",
    "        \n",
    "        merged_annotations = []\n",
    "        \n",
    "        merged_annotations.append(\n",
    "            {\n",
    "                \"bbox\": img1_annotations[1].tolist(),\n",
    "                \"label\": img1_annotations[0]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        new_bbox = [\n",
    "            ()\n",
    "        ]\n",
    "    \n",
    "    def parse_annotation(self, annotation_path):\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        image_width = int(root.find('size/width').text)\n",
    "        image_height = int(root.find('size/height').text)\n",
    "        \n",
    "        label = None\n",
    "        bbox = None\n",
    "        for obj in root.findall(\"object\"):\n",
    "            name = obj.find(\"name\").text\n",
    "            \n",
    "            if label is None:\n",
    "                label = name\n",
    "                xmin = int(obj.find('bndbox/xmin').text)\n",
    "                ymin = int(obj.find('bndbox/ymin').text)\n",
    "                xmax = int(obj.find('bndbox/xmax').text)\n",
    "                ymax = int(obj.find('bndbox/ymax').text)\n",
    "                \n",
    "                bbox = [\n",
    "                    xmin / image_width,\n",
    "                    ymin / image_height,\n",
    "                    xmax / image_width,\n",
    "                    ymax / image_height,\n",
    "                ]\n",
    "        \n",
    "        label_num = 0 if label == 'cat' else 1 if label =='dog' else -1\n",
    "        \n",
    "        return label_num, torch.tensor(bbox, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
